{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25/50/75% Data splits (stratified)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 25%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Custom Dataset for loading images and extracting patches based on nuclear density\n",
    "class HistologyDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_path, transform=None, patch_size=299, overlap=0.5, threshold=1.587, min_blue_density=0.02):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "        self.threshold = threshold\n",
    "        self.min_blue_density = min_blue_density\n",
    "\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.image_paths = [os.path.join(image_dir, fname) for fname in self.data.iloc[:, 0]]\n",
    "        self.labels = self.data.iloc[:, 1].values\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(np.unique(self.labels))}\n",
    "        self.labels = np.array([self.label_to_idx[label] for label in self.labels], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        patches, patch_labels = self.extract_patches(image, label)\n",
    "        if self.transform:\n",
    "            patches = [self.transform(patch) for patch in patches]\n",
    "        return patches, patch_labels\n",
    "\n",
    "    def extract_patches(self, image, label):\n",
    "        patches = []\n",
    "        patch_labels = []\n",
    "        height, width, _ = image.shape\n",
    "        stride = int(self.patch_size * (1 - self.overlap))\n",
    "        for y in range(0, height - self.patch_size + 1, stride):\n",
    "            for x in range(0, width - self.patch_size + 1, stride):\n",
    "                patch = image[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                if self.is_nucleus_dense(patch):\n",
    "                    patches.append(patch)\n",
    "                    patch_labels.append(label)\n",
    "        return patches, patch_labels\n",
    "\n",
    "    def is_nucleus_dense(self, patch):\n",
    "        hsv_patch = cv2.cvtColor(patch, cv2.COLOR_RGB2HSV)\n",
    "        blue_mask = (hsv_patch[:, :, 0] > self.threshold).astype(np.uint8)\n",
    "        blue_density = np.sum(blue_mask) / (patch.shape[0] * patch.shape[1])\n",
    "        return blue_density > self.min_blue_density\n",
    "\n",
    "def create_balanced_subset(dataset, percentage):\n",
    "    class_counts = np.bincount(dataset.labels)\n",
    "    min_class_count = min(class_counts)\n",
    "    subset_size_per_class = int(min_class_count * percentage)\n",
    "    indices_per_class = []\n",
    "    for class_label in range(len(class_counts)):\n",
    "        class_indices = np.where(dataset.labels == class_label)[0]\n",
    "        selected_indices = np.random.choice(class_indices, subset_size_per_class, replace=False)\n",
    "        indices_per_class.extend(selected_indices)\n",
    "    return indices_per_class\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class ModifiedInceptionV3(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ModifiedInceptionV3, self).__init__()\n",
    "        self.inception = models.inception_v3(pretrained=True)\n",
    "        self.inception.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.inception.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.inception.fc.in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.inception(x)\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "        return outputs\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for patches, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            patches = torch.cat([patch.to(device) for patch in patches], dim=0)\n",
    "            if isinstance(labels, list) or isinstance(labels, tuple):\n",
    "                labels = torch.cat(labels, dim=0).to(device)\n",
    "            labels = labels.long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(patches)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Train Loss: {running_loss / len(train_loader):.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for patches, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "                patches = torch.cat([patch.to(device) for patch in patches], dim=0)\n",
    "                if isinstance(labels, list) or isinstance(labels, tuple):\n",
    "                    labels = torch.cat(labels, dim=0).to(device)\n",
    "                labels = labels.long()\n",
    "                outputs = model(patches)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"Validation Loss: {val_loss / len(val_loader):.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "def majority_voting(patch_predictions):\n",
    "    values, counts = np.unique(patch_predictions, return_counts=True)\n",
    "    majority_class = values[np.argmax(counts)]\n",
    "    return majority_class\n",
    "\n",
    "image_dir = r\"C:\\Users\\vamsv\\Downloads\\ICIAR2018_BACH_Challenge\\ICIAR2018_BACH_Challenge\\Photos\\images\"\n",
    "csv_path = r\"C:\\Users\\vamsv\\Downloads\\ICIAR2018_BACH_Challenge\\ICIAR2018_BACH_Challenge\\Photos\\microscopy_ground_truth.csv\"\n",
    "\n",
    "dataset = HistologyDataset(image_dir=image_dir, csv_path=csv_path, transform=transform)\n",
    "indices_25_percent = create_balanced_subset(dataset, percentage=0.25)\n",
    "subset_25_percent = torch.utils.data.Subset(dataset, indices_25_percent)\n",
    "\n",
    "train_size_25 = int(0.75 * len(subset_25_percent))\n",
    "val_size_25 = len(subset_25_percent) - train_size_25\n",
    "train_dataset_25, val_dataset_25 = random_split(subset_25_percent, [train_size_25, val_size_25])\n",
    "\n",
    "train_loader_25 = DataLoader(train_dataset_25, batch_size=4, shuffle=True)\n",
    "val_loader_25 = DataLoader(val_dataset_25, batch_size=4, shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ModifiedInceptionV3(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "train_model(model, train_loader_25, val_loader_25, criterion, optimizer, num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 50%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Custom Dataset for loading images and extracting patches based on nuclear density\n",
    "class HistologyDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_path, transform=None, patch_size=299, overlap=0.5, threshold=1.587, min_blue_density=0.02):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "        self.threshold = threshold\n",
    "        self.min_blue_density = min_blue_density\n",
    "\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.image_paths = [os.path.join(image_dir, fname) for fname in self.data.iloc[:, 0]]\n",
    "        self.labels = self.data.iloc[:, 1].values\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(np.unique(self.labels))}\n",
    "        self.labels = np.array([self.label_to_idx[label] for label in self.labels], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        patches, patch_labels = self.extract_patches(image, label)\n",
    "        if self.transform:\n",
    "            patches = [self.transform(patch) for patch in patches]\n",
    "        return patches, patch_labels\n",
    "\n",
    "    def extract_patches(self, image, label):\n",
    "        patches = []\n",
    "        patch_labels = []\n",
    "        height, width, _ = image.shape\n",
    "        stride = int(self.patch_size * (1 - self.overlap))\n",
    "        for y in range(0, height - self.patch_size + 1, stride):\n",
    "            for x in range(0, width - self.patch_size + 1, stride):\n",
    "                patch = image[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                if self.is_nucleus_dense(patch):\n",
    "                    patches.append(patch)\n",
    "                    patch_labels.append(label)\n",
    "        return patches, patch_labels\n",
    "\n",
    "    def is_nucleus_dense(self, patch):\n",
    "        hsv_patch = cv2.cvtColor(patch, cv2.COLOR_RGB2HSV)\n",
    "        blue_mask = (hsv_patch[:, :, 0] > self.threshold).astype(np.uint8)\n",
    "        blue_density = np.sum(blue_mask) / (patch.shape[0] * patch.shape[1])\n",
    "        return blue_density > self.min_blue_density\n",
    "\n",
    "def create_balanced_subset(dataset, percentage):\n",
    "    class_counts = np.bincount(dataset.labels)\n",
    "    min_class_count = min(class_counts)\n",
    "    subset_size_per_class = int(min_class_count * percentage)\n",
    "    indices_per_class = []\n",
    "    for class_label in range(len(class_counts)):\n",
    "        class_indices = np.where(dataset.labels == class_label)[0]\n",
    "        selected_indices = np.random.choice(class_indices, subset_size_per_class, replace=False)\n",
    "        indices_per_class.extend(selected_indices)\n",
    "    return indices_per_class\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class ModifiedInceptionV3(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ModifiedInceptionV3, self).__init__()\n",
    "        self.inception = models.inception_v3(pretrained=True)\n",
    "        self.inception.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.inception.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.inception.fc.in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.inception(x)\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "        return outputs\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for patches, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            patches = torch.cat([patch.to(device) for patch in patches], dim=0)\n",
    "            if isinstance(labels, list) or isinstance(labels, tuple):\n",
    "                labels = torch.cat(labels, dim=0).to(device)\n",
    "            labels = labels.long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(patches)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Train Loss: {running_loss / len(train_loader):.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for patches, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "                patches = torch.cat([patch.to(device) for patch in patches], dim=0)\n",
    "                if isinstance(labels, list) or isinstance(labels, tuple):\n",
    "                    labels = torch.cat(labels, dim=0).to(device)\n",
    "                labels = labels.long()\n",
    "                outputs = model(patches)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"Validation Loss: {val_loss / len(val_loader):.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "def majority_voting(patch_predictions):\n",
    "    values, counts = np.unique(patch_predictions, return_counts=True)\n",
    "    majority_class = values[np.argmax(counts)]\n",
    "    return majority_class\n",
    "\n",
    "image_dir = r\"C:\\Users\\vamsv\\Downloads\\ICIAR2018_BACH_Challenge\\ICIAR2018_BACH_Challenge\\Photos\\images\"\n",
    "csv_path = r\"C:\\Users\\vamsv\\Downloads\\ICIAR2018_BACH_Challenge\\ICIAR2018_BACH_Challenge\\Photos\\microscopy_ground_truth.csv\"\n",
    "\n",
    "dataset = HistologyDataset(image_dir=image_dir, csv_path=csv_path, transform=transform)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ModifiedInceptionV3(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "indices_50_percent = create_balanced_subset(dataset, percentage=0.50)\n",
    "subset_50_percent = torch.utils.data.Subset(dataset, indices_50_percent)\n",
    "\n",
    "train_size_50 = int(0.75 * len(subset_50_percent))\n",
    "val_size_50 = len(subset_50_percent) - train_size_50\n",
    "train_dataset_50, val_dataset_50 = random_split(subset_50_percent, [train_size_50, val_size_50])\n",
    "\n",
    "train_loader_50 = DataLoader(train_dataset_50, batch_size=4, shuffle=True)\n",
    "val_loader_50 = DataLoader(val_dataset_50, batch_size=4, shuffle=False)\n",
    "\n",
    "train_model(model, train_loader_50, val_loader_50, criterion, optimizer, num_epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 75%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# Custom Dataset for loading images and extracting patches based on nuclear density\n",
    "class HistologyDataset(Dataset):\n",
    "    def __init__(self, image_dir, csv_path, transform=None, patch_size=299, overlap=0.5, threshold=1.587, min_blue_density=0.02):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.patch_size = patch_size\n",
    "        self.overlap = overlap\n",
    "        self.threshold = threshold\n",
    "        self.min_blue_density = min_blue_density\n",
    "\n",
    "        self.data = pd.read_csv(csv_path)\n",
    "        self.image_paths = [os.path.join(image_dir, fname) for fname in self.data.iloc[:, 0]]\n",
    "        self.labels = self.data.iloc[:, 1].values\n",
    "        self.label_to_idx = {label: idx for idx, label in enumerate(np.unique(self.labels))}\n",
    "        self.labels = np.array([self.label_to_idx[label] for label in self.labels], dtype=np.int64)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label = self.labels[idx]\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        image = np.array(image)\n",
    "        patches, patch_labels = self.extract_patches(image, label)\n",
    "        if self.transform:\n",
    "            patches = [self.transform(patch) for patch in patches]\n",
    "        return patches, patch_labels\n",
    "\n",
    "    def extract_patches(self, image, label):\n",
    "        patches = []\n",
    "        patch_labels = []\n",
    "        height, width, _ = image.shape\n",
    "        stride = int(self.patch_size * (1 - self.overlap))\n",
    "        for y in range(0, height - self.patch_size + 1, stride):\n",
    "            for x in range(0, width - self.patch_size + 1, stride):\n",
    "                patch = image[y:y+self.patch_size, x:x+self.patch_size]\n",
    "                if self.is_nucleus_dense(patch):\n",
    "                    patches.append(patch)\n",
    "                    patch_labels.append(label)\n",
    "        return patches, patch_labels\n",
    "\n",
    "    def is_nucleus_dense(self, patch):\n",
    "        hsv_patch = cv2.cvtColor(patch, cv2.COLOR_RGB2HSV)\n",
    "        blue_mask = (hsv_patch[:, :, 0] > self.threshold).astype(np.uint8)\n",
    "        blue_density = np.sum(blue_mask) / (patch.shape[0] * patch.shape[1])\n",
    "        return blue_density > self.min_blue_density\n",
    "\n",
    "def create_balanced_subset(dataset, percentage):\n",
    "    class_counts = np.bincount(dataset.labels)\n",
    "    min_class_count = min(class_counts)\n",
    "    subset_size_per_class = int(min_class_count * percentage)\n",
    "    indices_per_class = []\n",
    "    for class_label in range(len(class_counts)):\n",
    "        class_indices = np.where(dataset.labels == class_label)[0]\n",
    "        selected_indices = np.random.choice(class_indices, subset_size_per_class, replace=False)\n",
    "        indices_per_class.extend(selected_indices)\n",
    "    return indices_per_class\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(180),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class ModifiedInceptionV3(nn.Module):\n",
    "    def __init__(self, num_classes=4):\n",
    "        super(ModifiedInceptionV3, self).__init__()\n",
    "        self.inception = models.inception_v3(pretrained=True)\n",
    "        self.inception.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.inception.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(self.inception.fc.in_features, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.inception(x)\n",
    "        if isinstance(outputs, tuple):\n",
    "            outputs = outputs[0]\n",
    "        return outputs\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=50):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for patches, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Training\"):\n",
    "            patches = torch.cat([patch.to(device) for patch in patches], dim=0)\n",
    "            if isinstance(labels, list) or isinstance(labels, tuple):\n",
    "                labels = torch.cat(labels, dim=0).to(device)\n",
    "            labels = labels.long()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(patches)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "        train_acc = 100 * correct / total\n",
    "        print(f\"Train Loss: {running_loss / len(train_loader):.4f}, Train Accuracy: {train_acc:.2f}%\")\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for patches, labels in tqdm(val_loader, desc=f\"Epoch {epoch+1}/{num_epochs} - Validation\"):\n",
    "                patches = torch.cat([patch.to(device) for patch in patches], dim=0)\n",
    "                if isinstance(labels, list) or isinstance(labels, tuple):\n",
    "                    labels = torch.cat(labels, dim=0).to(device)\n",
    "                labels = labels.long()\n",
    "                outputs = model(patches)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "        val_acc = 100 * correct / total\n",
    "        print(f\"Validation Loss: {val_loss / len(val_loader):.4f}, Validation Accuracy: {val_acc:.2f}%\")\n",
    "\n",
    "def majority_voting(patch_predictions):\n",
    "    values, counts = np.unique(patch_predictions, return_counts=True)\n",
    "    majority_class = values[np.argmax(counts)]\n",
    "    return majority_class\n",
    "\n",
    "image_dir = r\"C:\\Users\\vamsv\\Downloads\\ICIAR2018_BACH_Challenge\\ICIAR2018_BACH_Challenge\\Photos\\images\"\n",
    "csv_path = r\"C:\\Users\\vamsv\\Downloads\\ICIAR2018_BACH_Challenge\\ICIAR2018_BACH_Challenge\\Photos\\microscopy_ground_truth.csv\"\n",
    "\n",
    "dataset = HistologyDataset(image_dir=image_dir, csv_path=csv_path, transform=transform)\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ModifiedInceptionV3(num_classes=4).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)\n",
    "\n",
    "indices_75_percent = create_balanced_subset(dataset, percentage=0.75)\n",
    "subset_75_percent = torch.utils.data.Subset(dataset, indices_75_percent)\n",
    "\n",
    "train_size_75 = int(0.75 * len(subset_75_percent))\n",
    "val_size_75 = len(subset_75_percent) - train_size_75\n",
    "train_dataset_75, val_dataset_75 = random_split(subset_75_percent, [train_size_75, val_size_75])\n",
    "\n",
    "train_loader_75 = DataLoader(train_dataset_75, batch_size=4, shuffle=True)\n",
    "val_loader_75 = DataLoader(val_dataset_75, batch_size=4, shuffle=False)\n",
    "\n",
    "train_model(model, train_loader_75, val_loader_75, criterion, optimizer, num_epochs=50)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
